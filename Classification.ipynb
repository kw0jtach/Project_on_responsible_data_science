{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2caf62",
   "metadata": {},
   "source": [
    "# Income Classifier on Adult Dataset\n",
    "\n",
    "Classifier to predict whether someone will have income \">50K\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a6016",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import AdultDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report,ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c026f1",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess the Adult Dataset\n",
    "\n",
    "We use **custom preprocessing** to align with the project requirements:\n",
    "- **Age**: Binarized using median threshold\n",
    "- **Sex**: Binary (Male=1, Female=0)  \n",
    "- **Race**: Simplified to binary (White=1, non-White=0)\n",
    "\n",
    "This preprocessing ensures consistency across all tasks (Classification, Fairness, Privacy, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2933142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom preprocessing function (aligned with Fairness.ipynb)\n",
    "def custom_preprocessing(df):\n",
    "    \"\"\"\n",
    "    Binarize age, encode race/sex, and drop raw columns to expose protected attributes explicitly.\n",
    "    This ensures consistency across all project tasks.\n",
    "    \"\"\"\n",
    "    median_age = df['age'].median()\n",
    "    df['age_binary'] = (df['age'] > median_age).astype(float)\n",
    "    df.drop(columns=['age'], inplace=True)\n",
    "    df['race'] = (df['race'] == 'White').astype(float)\n",
    "    df['sex'] = (df['sex'] == 'Male').astype(float)\n",
    "    return df\n",
    "\n",
    "# Load dataset with custom preprocessing\n",
    "dataset = AdultDataset(\n",
    "    custom_preprocessing=custom_preprocessing,\n",
    "    protected_attribute_names=['age_binary', 'sex'],\n",
    "    privileged_classes=[np.array([1.0]), np.array([1.0])]\n",
    ")\n",
    "\n",
    "# Convert to pandas for exploration\n",
    "df = pd.DataFrame(dataset.features, columns=dataset.feature_names)\n",
    "df['income'] = dataset.labels.ravel()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nIncome distribution:\")\n",
    "print(df['income'].value_counts())\n",
    "print(f\"\\nFeature names: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61007456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the binarized age feature\n",
    "print(\"Age binary distribution:\")\n",
    "print(df['age_binary'].value_counts())\n",
    "print(f\"\\nAge binary mean: {df['age_binary'].mean():.4f}\")\n",
    "print(f\"(Should be close to 0.5 since we used median threshold)\")\n",
    "\n",
    "# Check protected attributes\n",
    "print(f\"\\nSex distribution (1=Male, 0=Female):\")\n",
    "print(df['sex'].value_counts())\n",
    "print(f\"\\nRace distribution (1=White, 0=non-White):\")\n",
    "print(df['race'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263b5ef",
   "metadata": {},
   "source": [
    "## 3. Prepare Features and Target\n",
    "\n",
    "Extract features (X) and target (y) for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop(['income'], axis=1)  # All features (including age_binary, sex, race)\n",
    "y = df['income']  # Target: income classification\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature names: {list(X.columns)}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33bc644",
   "metadata": {},
   "source": [
    "## 4. Split Data into Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6015b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split: 70% train, 15% validation, 15% test (aligned with Fairness.ipynb)\n",
    "# First split: 70% train, 30% temp (validation + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y  # Using random_state=1 for consistency with Fairness\n",
    ")\n",
    "\n",
    "# Second split: Split temp into 50% validation, 50% test (15% each of total)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=1, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test.shape[0]} ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nClass distribution in validation set:\")\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5140c",
   "metadata": {},
   "source": [
    "## 5. Feature Scaling\n",
    "\n",
    "The idea is to put features on a similar scale so that no single feature dominates the learning process due to its magnitude. This is especially important for algorithms like Logistic Regression, which are sensitive to the scale of input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a324229",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) # computes mean and std, then scales\n",
    "X_val_scaled = scaler.transform(X_val) # scales validation set\n",
    "X_test_scaled = scaler.transform(X_test) # scales test set\n",
    "\n",
    "print(\"Features scaled using StandardScaler\")\n",
    "print(f\"Training set scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"Validation set scaled shape: {X_val_scaled.shape}\")\n",
    "print(f\"Test set scaled shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887abc09",
   "metadata": {},
   "source": [
    "## 6. Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000, random_state=1)\n",
    "lr_classifier.fit(X_train_scaled, y_train)\n",
    "print(\"✓ Logistic Regression trained successfully\")\n",
    "print(f\"  Model: {type(lr_classifier).__name__}\")\n",
    "print(f\"  Features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"  Training samples: {X_train_scaled.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841be31",
   "metadata": {},
   "source": [
    "### Saving \"The Classifier\"\n",
    "\n",
    "This is **the base classifier** referenced in the project statement (Section 1: Classification). \n",
    "We save it with a clear name for reuse in subsequent tasks (Fairness, Privacy, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Build artifact with all necessary components for reusability\n",
    "artifact = {\n",
    "    \"model\": lr_classifier,           # the trained classifier\n",
    "    \"scaler\": scaler,                 # the trained StandardScaler\n",
    "    \"feature_names\": list(X.columns), # feature names for consistency\n",
    "    \"preprocessing\": \"custom\",        # indicate custom preprocessing was used\n",
    "    \"protected_attributes\": [\"age_binary\", \"sex\"]  # for fairness analysis\n",
    "}\n",
    "\n",
    "# Save THE CLASSIFIER (primary reference for the entire project)\n",
    "joblib.dump(artifact, \"models/the_classifier.joblib\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"✓ THE CLASSIFIER saved successfully!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Location: models/the_classifier.joblib\")\n",
    "print(f\"  Model: {type(lr_classifier).__name__}\")\n",
    "print(f\"  Features: {len(artifact['feature_names'])}\")\n",
    "print(f\"  Preprocessing: Custom (age_binary, binary race/sex)\")\n",
    "print(f\"  Protected attributes: {artifact['protected_attributes']}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThis model will be reused in:\")\n",
    "print(\"  - Fairness.ipynb (fairness assessment)\")\n",
    "print(\"  - Privacy tasks (baseline comparison)\")\n",
    "print(\"  - Explainability analysis\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd963e6",
   "metadata": {},
   "source": [
    "## 7. Measure Performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddad3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : add confusion matrix visualization -------------OK\n",
    "# Predict on validation set\n",
    "y_val_pred = lr_classifier.predict(X_val_scaled)\n",
    "\n",
    "# Calculate validation metrics\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_precision = precision_score(y_val, y_val_pred)\n",
    "val_recall = recall_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"VALIDATION SET PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {val_accuracy:.4f}\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall:    {val_recall:.4f}\")\n",
    "print(f\"F1-Score:  {val_f1:.4f}\")\n",
    "\n",
    "print(\"Detailed Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=['<=50K', '>50K']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_val)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_val, display_labels=['<=50K', '>50K'])\n",
    "disp.plot()\n",
    "plt.title(\"Validation Set - Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360e15f",
   "metadata": {},
   "source": [
    "## 8. Measure Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990da7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_test_pred = lr_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST SET PERFORMANCE (THE CLASSIFIER)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['<=50K', '>50K']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_test)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=['<=50K', '>50K'])\n",
    "disp.plot()\n",
    "plt.title(\"Test Set - THE CLASSIFIER Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3666d5",
   "metadata": {},
   "source": [
    "## Summary: Task 1 - Classification Complete ✅\n",
    "\n",
    "**THE CLASSIFIER** has been successfully trained and saved for reuse throughout the project.\n",
    "\n",
    "### Key Details:\n",
    "- **Model**: Logistic Regression (max_iter=1000)\n",
    "- **Dataset**: Adult Dataset with custom preprocessing\n",
    "- **Features**: Age (binary), Sex (binary), Race (binary), and other socioeconomic features\n",
    "- **Protected Attributes**: `age_binary`, `sex` (for fairness analysis)\n",
    "- **Data Split**: 70% train / 15% validation / 15% test\n",
    "- **Saved Location**: `models/the_classifier.joblib`\n",
    "\n",
    "### Next Steps:\n",
    "1. **Task 2 - Fairness**: Load THE CLASSIFIER and assess fairness metrics\n",
    "2. **Task 3 - Privacy**: Use as baseline for privacy-preserving classifier comparison\n",
    "3. **Task 5 - Explainability**: Analyze confident mistakes and feature importance\n",
    "\n",
    "### Important Notes:\n",
    "- All subsequent notebooks should **load** this classifier (not retrain)\n",
    "- Custom preprocessing must be applied consistently across all tasks\n",
    "- The saved artifact includes model, scaler, and feature names for consistency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
