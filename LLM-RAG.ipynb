{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f74b0ba",
   "metadata": {},
   "source": [
    "# Task 6: Explainability and LLMs\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we build a **natural language interface** to present machine learning explanations in human-friendly text. We use **LIME** (Local Interpretable Model-agnostic Explanations) via the original `lime` library and leverage a local LLM (Google Gemma via LM Studio) to generate accessible explanations.\n",
    "\n",
    "### Key Objectives:\n",
    "1. **Connect to Local LLM**: Set up LM Studio connection with Gemma model\n",
    "2. **Load Explainability Data**: Generate LIME explanations for confident mistakes\n",
    "3. **Build Explanation Functions**: Create simple and advanced interfaces\n",
    "4. **Generate Natural Language Explanations**: Transform technical outputs into human-readable text\n",
    "\n",
    "### Why LIME + Direct Context (No RAG)?\n",
    "- **LIME** provides instance-specific, human-relatable explanations\n",
    "- Our data is small (~10 instances) and fits in a single prompt context\n",
    "- RAG would add complexity without practical benefit for our use case\n",
    "\n",
    "See `doc/explainability-llms.md` for detailed rationale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d164d0c",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67574a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aif360.datasets import AdultDataset\n",
    "\n",
    "# LIME - the original implementation (Python 3.12+ compatible)\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# OpenAI-compatible client for LM Studio\n",
    "from openai import OpenAI\n",
    "\n",
    "print(\"✓ Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0beabd0",
   "metadata": {},
   "source": [
    "## 2. Connect to LM Studio\n",
    "\n",
    "**Prerequisites:**\n",
    "1. LM Studio is installed and running\n",
    "2. A Gemma model is downloaded and loaded\n",
    "3. Local server is started (Developer tab → Start Server)\n",
    "\n",
    "The server runs on `http://127.0.0.1:1234`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7db05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to LM Studio!\n",
      "Available models:\n",
      "  - google/gemma-3-12b\n",
      "  - text-embedding-nomic-embed-text-v1.5\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI-compatible client for LM Studio\n",
    "client = OpenAI(\n",
    "    api_key=\"lm-studio\",  # placeholder - not validated by LM Studio\n",
    "    base_url=\"http://127.0.0.1:1234/v1\"  # must include /v1\n",
    ")\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    print(\"Connected to LM Studio!\")\n",
    "    print(\"Available models:\")\n",
    "    for model in models.data:\n",
    "        print(f\"  - {model.id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to LM Studio: {e}\")\n",
    "    print(\"\\nMake sure LM Studio is running with a model loaded and server started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "642e3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - adjust model name if using a different variant\n",
    "MODEL_NAME = \"google/gemma-3-12b\"  # Change this to match your loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b98777",
   "metadata": {},
   "source": [
    "## 3. Load Data and Private Classifier\n",
    "\n",
    "We reload the data and model from Task 5 to generate LIME explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244bb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded THE PRIVATE CLASSIFIER\n",
      "  - Epsilon: 1.0\n",
      "  - Model type: LogisticRegression\n",
      "  - Number of features: 98\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Load the Private Classifier\n",
    "model_path = \"models/the_private_classifier.joblib\"\n",
    "artifact = joblib.load(model_path)\n",
    "\n",
    "clf_private = artifact[\"model\"]\n",
    "scaler_private = artifact[\"scaler\"]\n",
    "feature_names = artifact[\"feature_names\"]\n",
    "epsilon = artifact[\"epsilon\"]\n",
    "\n",
    "print(f\"Loaded THE PRIVATE CLASSIFIER\")\n",
    "print(f\"  - Epsilon: {epsilon}\")\n",
    "print(f\"  - Model type: {type(clf_private).__name__}\")\n",
    "print(f\"  - Number of features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349019ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded: (45222, 99)\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Load and Prepare Dataset\n",
    "def custom_preprocessing(df):\n",
    "    \"\"\"Binarize age, encode race/sex - consistent with previous tasks.\"\"\"\n",
    "    median_age = df['age'].median()\n",
    "    df['age_binary'] = (df['age'] > median_age).astype(float)\n",
    "    df.drop(columns=['age'], inplace=True)\n",
    "    df['race'] = (df['race'] == 'White').astype(float)\n",
    "    df['sex'] = (df['sex'] == 'Male').astype(float)\n",
    "    return df\n",
    "\n",
    "# Load dataset\n",
    "dataset = AdultDataset(\n",
    "    custom_preprocessing=custom_preprocessing,\n",
    "    protected_attribute_names=['age_binary', 'sex'],\n",
    "    privileged_classes=[np.array([1.0]), np.array([1.0])]\n",
    ")\n",
    "\n",
    "df_true = pd.DataFrame(dataset.features, columns=dataset.feature_names)\n",
    "df_true['income'] = dataset.labels.ravel()\n",
    "\n",
    "print(f\"Dataset loaded: {df_true.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd0acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Private dataset created (ε=1.0, truth probability: 47.5%)\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Apply Differential Privacy (reproduce from Task 5)\n",
    "def dp_randomized_response(categories, epsilon, k=4):\n",
    "    \"\"\"Implements randomized response mechanism for differential privacy.\"\"\"\n",
    "    categories = np.asarray(categories, dtype=int)\n",
    "    n = len(categories)\n",
    "    exp_eps = np.exp(epsilon)\n",
    "    p = exp_eps / (exp_eps + k - 1)\n",
    "    \n",
    "    reports = np.empty_like(categories)\n",
    "    u = np.random.rand(n)\n",
    "    same = (u < p)\n",
    "    reports[same] = categories[same]\n",
    "    \n",
    "    num_flip = np.sum(~same)\n",
    "    if num_flip > 0:\n",
    "        true_vals = categories[~same]\n",
    "        alt = np.random.randint(0, k-1, size=num_flip)\n",
    "        alt += (alt >= true_vals).astype(int)\n",
    "        reports[~same] = alt\n",
    "    \n",
    "    return reports, p\n",
    "\n",
    "# Create private dataset\n",
    "df_true['age_sex_cat'] = (df_true['age_binary'].astype(int) * 2 + df_true['sex'].astype(int))\n",
    "np.random.seed(42)\n",
    "reports, p_truth = dp_randomized_response(df_true['age_sex_cat'], epsilon, k=4)\n",
    "\n",
    "df_private = df_true.copy()\n",
    "df_private['age_binary'] = (reports // 2).astype(float)\n",
    "df_private['sex'] = (reports % 2).astype(float)\n",
    "\n",
    "df_true.drop(columns=['age_sex_cat'], inplace=True)\n",
    "df_private.drop(columns=['age_sex_cat'], inplace=True)\n",
    "\n",
    "print(f\"Private dataset created (ε={epsilon}, truth probability: {p_truth:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a7995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found 495 confident mistakes (>80% confidence)\n",
      "  Top 10 will be used for LIME explanations\n"
     ]
    }
   ],
   "source": [
    "# 3.4 Identify Confident Mistakes\n",
    "X_private = df_private[feature_names].values\n",
    "y_private = df_private['income'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_private, y_private, test_size=0.3, random_state=1, stratify=y_private\n",
    ")\n",
    "\n",
    "df_private_train, df_private_test = train_test_split(\n",
    "    df_private, test_size=0.3, random_state=1, stratify=df_private['income']\n",
    ")\n",
    "\n",
    "# Get predictions\n",
    "X_test_scaled = scaler_private.transform(X_test)\n",
    "y_pred = clf_private.predict(X_test_scaled)\n",
    "y_proba = clf_private.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Find confident mistakes\n",
    "results_df = df_private_test.copy()\n",
    "results_df['true_label'] = y_test\n",
    "results_df['prediction'] = y_pred\n",
    "results_df['probability'] = y_proba\n",
    "results_df['confidence'] = np.where(y_pred == 1, y_proba, 1 - y_proba)\n",
    "\n",
    "mistakes = results_df[results_df['true_label'] != results_df['prediction']]\n",
    "confident_mistakes = mistakes[mistakes['confidence'] > 0.80].sort_values(by='confidence', ascending=False)\n",
    "top_10_mistakes = confident_mistakes.head(10)\n",
    "\n",
    "print(f\"Found {len(confident_mistakes)} confident mistakes (>80% confidence)\")\n",
    "print(f\"  Top 10 will be used for LIME explanations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0aa214",
   "metadata": {},
   "source": [
    "## 4. Generate LIME Explanations\n",
    "\n",
    "We use OmniXAI's LIME implementation to generate local explanations for each confident mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e4e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LIME explainer ready\n",
      "  Categorical features: ['age_binary', 'sex', 'race']\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Setup LIME Tabular Explainer\n",
    "# Identify categorical feature indices\n",
    "categorical_features = [feature_names.index(f) for f in ['age_binary', 'sex', 'race'] if f in feature_names]\n",
    "categorical_names = {i: ['0', '1'] for i in categorical_features}\n",
    "\n",
    "# Create LIME explainer\n",
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_train,\n",
    "    feature_names=feature_names,\n",
    "    class_names=['≤50K', '>50K'],\n",
    "    categorical_features=categorical_features,\n",
    "    categorical_names=categorical_names,\n",
    "    mode='classification',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define prediction function for LIME\n",
    "def predict_proba_fn(X):\n",
    "    \"\"\"Wrapper for the private classifier's predict_proba.\"\"\"\n",
    "    X_scaled = scaler_private.transform(X)\n",
    "    return clf_private.predict_proba(X_scaled)\n",
    "\n",
    "print(\"LIME explainer ready\")\n",
    "print(f\"  Categorical features: {[feature_names[i] for i in categorical_features]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae65b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LIME explanations for 10 instances...\n",
      "✓ LIME explanations generated\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Generate LIME Explanations for Confident Mistakes\n",
    "mistake_indices = top_10_mistakes.index.tolist()\n",
    "print(f\"Generating LIME explanations for {len(mistake_indices)} instances...\")\n",
    "\n",
    "# Store raw LIME explanation objects\n",
    "lime_raw_explanations = {}\n",
    "for idx in mistake_indices:\n",
    "    instance = df_private_test.loc[idx, feature_names].values\n",
    "    exp = lime_explainer.explain_instance(\n",
    "        instance, \n",
    "        predict_proba_fn, \n",
    "        num_features=10,  # Top 10 features\n",
    "        num_samples=1000\n",
    "    )\n",
    "    lime_raw_explanations[idx] = exp\n",
    "\n",
    "print(\"LIME explanations generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b9bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stored LIME data for 10 instances\n",
      "  Available instance IDs: [29306, 9839, 8231, 8113, 34957, 10949, 19246, 5569, 16278, 44264]\n"
     ]
    }
   ],
   "source": [
    "# 4.3 Extract and Store LIME Data in a Structured Format\n",
    "lime_data_store = {}\n",
    "\n",
    "for idx in mistake_indices:\n",
    "    instance_data = top_10_mistakes.loc[idx]\n",
    "    exp = lime_raw_explanations[idx]\n",
    "    \n",
    "    # Extract feature contributions as list of (feature_name, value, importance)\n",
    "    # LIME returns list of (feature_description, importance) tuples\n",
    "    lime_features = []\n",
    "    instance_values = df_private_test.loc[idx, feature_names]\n",
    "    \n",
    "    for feature_desc, importance in exp.as_list():\n",
    "        # feature_desc is like \"marital-status=Married\" or \"age > 0.5\"\n",
    "        # Extract the base feature name\n",
    "        for fn in feature_names:\n",
    "            if fn in feature_desc:\n",
    "                lime_features.append((feature_desc, instance_values[fn], importance))\n",
    "                break\n",
    "    \n",
    "    lime_data_store[idx] = {\n",
    "        'instance_id': idx,\n",
    "        'prediction': int(instance_data['prediction']),\n",
    "        'true_label': int(instance_data['true_label']),\n",
    "        'confidence': instance_data['confidence'],\n",
    "        'is_correct': instance_data['prediction'] == instance_data['true_label'],\n",
    "        'age_binary': instance_data['age_binary'],\n",
    "        'sex': instance_data['sex'],\n",
    "        'race': instance_data['race'],\n",
    "        'lime_features': lime_features,\n",
    "        'lime_explanation': exp  # Keep raw explanation for potential visualization\n",
    "    }\n",
    "\n",
    "print(f\"Stored LIME data for {len(lime_data_store)} instances\")\n",
    "print(f\"  Available instance IDs: {list(lime_data_store.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c312b1ad",
   "metadata": {},
   "source": [
    "## 5. Build LLM Explanation Interface\n",
    "\n",
    "### 5.1 Simple Function Interface (Baseline)\n",
    "\n",
    "A straightforward function that takes an instance ID and returns a natural language explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953081bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Context builder ready\n"
     ]
    }
   ],
   "source": [
    "# System prompt that establishes the LLM's role\n",
    "SYSTEM_PROMPT = \"\"\"You are an AI assistant that explains machine learning predictions in simple, human-friendly language. \n",
    "\n",
    "You have access to LIME explanations that show which features influenced a specific prediction and by how much. Positive scores push toward predicting HIGH income (>$50K), negative scores push toward LOW income (≤$50K).\n",
    "\n",
    "Guidelines:\n",
    "- Use plain language, avoid technical jargon\n",
    "- Explain feature contributions in terms of real-world meaning\n",
    "- Focus on the top 3-5 most important factors\n",
    "- Be honest if the prediction was wrong\n",
    "- Provide context about why certain features matter for income prediction\n",
    "- Keep responses concise but informative (2-3 paragraphs)\n",
    "\n",
    "The model predicts whether someone earns more than $50,000 per year based on census data.\"\"\"\n",
    "\n",
    "def build_instance_context(instance_id):\n",
    "    \"\"\"Build context string for a specific instance.\"\"\"\n",
    "    if instance_id not in lime_data_store:\n",
    "        return None\n",
    "    \n",
    "    data = lime_data_store[instance_id]\n",
    "    \n",
    "    # Format prediction info\n",
    "    pred_class = \">$50K (High Income)\" if data['prediction'] == 1 else \"≤$50K (Low Income)\"\n",
    "    true_class = \">$50K (High Income)\" if data['true_label'] == 1 else \"≤$50K (Low Income)\"\n",
    "    status = \"CORRECT\" if data['is_correct'] else \"INCORRECT\"\n",
    "    \n",
    "    # Format demographics\n",
    "    age_desc = \"older (>38 years)\" if data['age_binary'] == 1.0 else \"younger (≤38 years)\"\n",
    "    sex_desc = \"Male\" if data['sex'] == 1.0 else \"Female\"\n",
    "    race_desc = \"White\" if data['race'] == 1.0 else \"Non-White\"\n",
    "    \n",
    "    # Format LIME features (top 10)\n",
    "    lime_features = data['lime_features'][:10]\n",
    "    lime_str = \"\\n\".join([\n",
    "        f\"  {i+1}. {feat[0]}: value={feat[1]}, importance={feat[2]:.4f} ({'pushes toward HIGH' if feat[2] > 0 else 'pushes toward LOW'})\"\n",
    "        for i, feat in enumerate(lime_features)\n",
    "    ])\n",
    "    \n",
    "    context = f\"\"\"PREDICTION DETAILS:\n",
    "- Instance ID: {instance_id}\n",
    "- Model Predicted: {pred_class}\n",
    "- Confidence: {data['confidence']*100:.1f}%\n",
    "- Actual Income: {true_class}\n",
    "- Prediction Status: {status}\n",
    "\n",
    "PERSON'S DEMOGRAPHICS:\n",
    "- Age: {age_desc}\n",
    "- Sex: {sex_desc}\n",
    "- Race: {race_desc}\n",
    "\n",
    "LIME EXPLANATION (features that influenced this prediction, ranked by importance):\n",
    "{lime_str}\"\"\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "print(\"Context builder ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83196e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ explain_instance() function ready\n"
     ]
    }
   ],
   "source": [
    "def explain_instance(instance_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Generate a human-friendly explanation for a specific prediction.\n",
    "    \n",
    "    Args:\n",
    "        instance_id: The ID of the instance to explain (from confident mistakes)\n",
    "    \n",
    "    Returns:\n",
    "        Natural language explanation of the prediction\n",
    "    \"\"\"\n",
    "    # Build context\n",
    "    context = build_instance_context(instance_id)\n",
    "    if context is None:\n",
    "        return f\"Error: Instance {instance_id} not found. Available IDs: {list(lime_data_store.keys())}\"\n",
    "    \n",
    "    # Build the prompt\n",
    "    user_message = f\"\"\"Based on the following LIME explanation data, explain why the model made this prediction in plain language that a non-technical person could understand.\n",
    "\n",
    "{context}\n",
    "\n",
    "Please explain:\n",
    "1. What the model predicted and how confident it was\n",
    "2. The main factors that led to this prediction\n",
    "3. Whether the prediction was correct, and if not, why the model might have been misled\"\"\"\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error generating explanation: {e}\"\n",
    "\n",
    "print(\"explain_instance() function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663d994",
   "metadata": {},
   "source": [
    "### 5.2 Test the Simple Interface\n",
    "\n",
    "Let's test with one of the confident mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b0999c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining instance 29306...\n",
      "======================================================================\n",
      "The model incorrectly predicted that this person earns over $50,000 per year with 100% confidence. Unfortunately, their actual income is $50,000 or less. This means the model made a mistake!\n",
      "\n",
      "Here's what influenced the prediction: The biggest factor pushing the model towards a high-income prediction was a large \"capital gain\" - which represents profit from selling stocks or other assets. A high capital gain strongly suggests higher income. Surprisingly, several factors related to their country of origin (Italy, Cuba, England, Cambodia, Hungary) and education level (Preschool, Doctorate, Prof-school) pulled the model *away* from a high-income prediction, but these were outweighed by the impact of the capital gain. It's common for income models to consider where someone is originally from and their educational background - people who immigrated from certain countries or have lower levels of education sometimes earn less on average.\n",
      "\n",
      "Because the model focused so heavily on the capital gain, it overlooked other important factors. Capital gains aren’t a consistent source of income; they're more like one-time windfalls. The model likely overemphasized this single factor and didn’t account for the person's actual circumstances or overall financial picture, leading to an inaccurate prediction.\n"
     ]
    }
   ],
   "source": [
    "# Test with the first confident mistake\n",
    "first_instance_id = mistake_indices[0]\n",
    "print(f\"Explaining instance {first_instance_id}...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "explanation = explain_instance(first_instance_id)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0f82cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining instance 9839...\n",
      "======================================================================\n",
      "Okay, let's break down why the model made its prediction for this person.\n",
      "\n",
      "The model incorrectly predicted that this individual earns $50,000 or less per year with a very high confidence of 99.9%. However, in reality, they actually earn more than $50,000! The main reason for this misjudgment seems to be the lack of capital gains (profit from investments).  The model strongly associated zero capital gains with lower incomes. Additionally, the person's country of origin – specifically being from Italy, France, and Taiwan – also contributed negatively toward a low-income prediction according to the model. \n",
      "\n",
      "Interestingly, some factors slightly pushed the prediction towards higher income, like having an occupation as a \"Private house servant\" or having only preschool education. The fact that this person doesn’t receive payment for their work (workclass=Without-pay) also pulled the prediction toward lower income. It's likely the negative impact of zero capital gains and specific countries of origin outweighed these positive influences, leading to the wrong conclusion. \n",
      "\n",
      "Income prediction models often rely on patterns observed in training data, and sometimes those patterns don’t perfectly apply to every individual. In this case, perhaps the model overemphasized the importance of capital gains or incorrectly associated certain origins with lower incomes for this particular person. It's a reminder that these predictions are estimates based on past trends and aren't always perfect!\n"
     ]
    }
   ],
   "source": [
    "# Test with another instance\n",
    "second_instance_id = mistake_indices[1]\n",
    "print(f\"Explaining instance {second_instance_id}...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "explanation = explain_instance(second_instance_id)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666c517b",
   "metadata": {},
   "source": [
    "### 5.3 Interactive Chat Interface (Advanced)\n",
    "\n",
    "A multi-turn conversation interface that maintains context and supports follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad202e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Interactive chat interface ready\n",
      "  Available instances: [29306, 9839, 8231, 8113, 34957, 10949, 19246, 5569, 16278, 44264]\n"
     ]
    }
   ],
   "source": [
    "class ExplainabilityChat:\n",
    "    \"\"\"Interactive chat interface for ML explanations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "        self.current_instance = None\n",
    "        \n",
    "        # Build a summary of available data for the LLM\n",
    "        self.available_instances = list(lime_data_store.keys())\n",
    "        \n",
    "    def set_instance(self, instance_id: int) -> str:\n",
    "        \"\"\"Set the current instance for discussion.\"\"\"\n",
    "        if instance_id not in lime_data_store:\n",
    "            return f\"Instance {instance_id} not found. Available: {self.available_instances}\"\n",
    "        \n",
    "        self.current_instance = instance_id\n",
    "        context = build_instance_context(instance_id)\n",
    "        \n",
    "        # Add context to conversation\n",
    "        context_message = f\"[Context loaded for Instance {instance_id}]\\n\\n{context}\"\n",
    "        self.messages.append({\"role\": \"system\", \"content\": context_message})\n",
    "        \n",
    "        return f\"Loaded instance {instance_id}. You can now ask questions about this prediction.\"\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"Send a message and get a response.\"\"\"\n",
    "        if self.current_instance is None and \"instance\" not in user_message.lower():\n",
    "            return \"Please first select an instance using set_instance(id), or ask about a specific instance.\"\n",
    "        \n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=self.messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=500\n",
    "            )\n",
    "            response = completion.choices[0].message.content\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the conversation.\"\"\"\n",
    "        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "        self.current_instance = None\n",
    "        return \"Conversation reset.\"\n",
    "    \n",
    "    def list_instances(self):\n",
    "        \"\"\"List available instances with summary.\"\"\"\n",
    "        print(\"Available instances for explanation:\")\n",
    "        print(\"-\" * 60)\n",
    "        for idx in self.available_instances:\n",
    "            data = lime_data_store[idx]\n",
    "            pred = \">50K\" if data['prediction'] == 1 else \"≤50K\"\n",
    "            true = \">50K\" if data['true_label'] == 1 else \"≤50K\"\n",
    "            status = \"\" if data['is_correct'] else \"\"\n",
    "            print(f\"  ID {idx}: Predicted {pred}, Actually {true} {status} (Conf: {data['confidence']*100:.1f}%)\")\n",
    "\n",
    "# Initialize the chat interface\n",
    "chat = ExplainabilityChat()\n",
    "print(\"Interactive chat interface ready\")\n",
    "print(f\"  Available instances: {chat.available_instances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8738e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available instances for explanation:\n",
      "------------------------------------------------------------\n",
      "  ID 29306: Predicted >50K, Actually ≤50K ✗ (Conf: 100.0%)\n",
      "  ID 9839: Predicted ≤50K, Actually >50K ✗ (Conf: 99.9%)\n",
      "  ID 8231: Predicted ≤50K, Actually >50K ✗ (Conf: 99.9%)\n",
      "  ID 8113: Predicted ≤50K, Actually >50K ✗ (Conf: 99.7%)\n",
      "  ID 34957: Predicted ≤50K, Actually >50K ✗ (Conf: 99.5%)\n",
      "  ID 10949: Predicted ≤50K, Actually >50K ✗ (Conf: 99.5%)\n",
      "  ID 19246: Predicted >50K, Actually ≤50K ✗ (Conf: 99.2%)\n",
      "  ID 5569: Predicted ≤50K, Actually >50K ✗ (Conf: 99.1%)\n",
      "  ID 16278: Predicted ≤50K, Actually >50K ✗ (Conf: 99.1%)\n",
      "  ID 44264: Predicted ≤50K, Actually >50K ✗ (Conf: 99.0%)\n"
     ]
    }
   ],
   "source": [
    "# List all available instances\n",
    "chat.list_instances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb066f6e",
   "metadata": {},
   "source": [
    "### 5.4 Demo: Interactive Chat Session\n",
    "\n",
    "Let's demonstrate a multi-turn conversation about a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a478e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded instance 29306. You can now ask questions about this prediction.\n"
     ]
    }
   ],
   "source": [
    "# Start a new conversation about an instance\n",
    "chat.reset()\n",
    "instance_to_discuss = mistake_indices[0]\n",
    "print(chat.set_instance(instance_to_discuss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78c7c380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Why did the model predict this person would have high income?\n",
      "------------------------------------------------------------\n",
      "Assistant: The model incorrectly predicted that this individual earns over $50,000 a year. It seems the biggest factor pushing the prediction towards a high income was their capital gain – essentially, profit made from selling stocks or other assets. A large capital gain like theirs (over $34,000) often signals higher overall wealth and income. Additionally, the model considered their education level; having attended preschool nudged the prediction slightly toward a higher income.\n",
      "\n",
      "However, several factors pulled the prediction *down* towards a lower income. The model penalized this person for being born in Italy or Cuba, and also for not having advanced degrees like a doctorate or attending prestigious schools such as professional school. Being married also lowered the predicted income, which can sometimes happen because traditionally, one partner might be the primary earner. \n",
      "\n",
      "Ultimately, even though the capital gain was significant, these negative influences outweighed it, but the model still got the prediction wrong! Income is complex and depends on many things beyond just education and country of origin; this instance highlights how even sophisticated models can make mistakes when trying to predict financial outcomes.\n"
     ]
    }
   ],
   "source": [
    "# First question\n",
    "response = chat.chat(\"Why did the model predict this person would have high income?\")\n",
    "print(\"User: Why did the model predict this person would have high income?\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd684fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Was this prediction correct? If not, what went wrong?\n",
      "------------------------------------------------------------\n",
      "Assistant: No, this prediction was incorrect. The model predicted the person earns over $50,000 per year (high income), but their actual income is $50,000 or less (low income).\n",
      "\n",
      "Here's what likely went wrong: While a large capital gain (profit from investments) strongly suggested a high income to the model, other factors pulled the prediction downwards. These included the person’s country of origin (Italy and Cuba), their education level (only preschool), and marital status (being married). The model gave too much weight to these negative influences compared to the positive influence of the capital gain, leading it astray. Essentially, the model focused on a few key indicators but didn't fully account for the nuances that affect someone's income.\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question (uses conversation history)\n",
    "response = chat.chat(\"Was this prediction correct? If not, what went wrong?\")\n",
    "print(\"User: Was this prediction correct? If not, what went wrong?\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b52f45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: In simple terms, what is the single most important factor that influenced this prediction?\n",
      "------------------------------------------------------------\n",
      "Assistant: The single biggest thing influencing the model’s incorrect prediction was the person's **capital gain**, which was over $34,000. This large profit from investments strongly suggested a high income to the model, but unfortunately wasn't enough to overcome other negative factors.\n"
     ]
    }
   ],
   "source": [
    "# Another follow-up\n",
    "response = chat.chat(\"In simple terms, what is the single most important factor that influenced this prediction?\")\n",
    "print(\"User: In simple terms, what is the single most important factor that influenced this prediction?\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff15a9c",
   "metadata": {},
   "source": [
    "## 6. Utility Functions\n",
    "\n",
    "Additional helper functions to explore different aspects of the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a8858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Utility functions ready\n"
     ]
    }
   ],
   "source": [
    "def explain_all_instances():\n",
    "    \"\"\"Generate explanations for all confident mistakes and display them.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"GENERATING EXPLANATIONS FOR ALL CONFIDENT MISTAKES\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for idx in lime_data_store.keys():\n",
    "        data = lime_data_store[idx]\n",
    "        pred = \">$50K\" if data['prediction'] == 1 else \"≤$50K\"\n",
    "        true = \">$50K\" if data['true_label'] == 1 else \"≤$50K\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Instance {idx}: Predicted {pred}, Actually {true}\")\n",
    "        print(f\"Confidence: {data['confidence']*100:.1f}%\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        explanation = explain_instance(idx)\n",
    "        print(explanation)\n",
    "        print()\n",
    "\n",
    "def compare_instances(id1: int, id2: int):\n",
    "    \"\"\"Compare explanations for two instances.\"\"\"\n",
    "    prompt = f\"\"\"Compare the following two predictions and explain the key differences in why the model made different predictions for each person.\n",
    "\n",
    "INSTANCE 1:\n",
    "{build_instance_context(id1)}\n",
    "\n",
    "INSTANCE 2:\n",
    "{build_instance_context(id2)}\n",
    "\n",
    "Please explain:\n",
    "1. What factors led to different predictions for these two people?\n",
    "2. Are there any surprising similarities or differences?\n",
    "3. What does this tell us about how the model makes decisions?\"\"\"\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=600\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "print(\"Utility functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcd18c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing instances 29306 and 9839...\n",
      "======================================================================\n",
      "Okay, let's break down why the model got these two predictions wrong and what we can learn from it. Both instances were incorrectly classified – predicting low income for someone who earned high income (Instance 1) and vice versa (Instance 2).\n",
      "\n",
      "**What led to different predictions?** The biggest difference lies in how the model interpreted \"capital gain.\" For Instance 1, a large capital gain (profit from selling an asset like stocks) strongly pushed the prediction *toward* a high income. This was the most important factor influencing the decision. Conversely, for Instance 2, the lack of any capital gain heavily influenced the model to predict a low income - and this had the largest influence on the prediction. Beyond that, both instances saw several \"native country\" features pulling in opposite directions – some countries were associated with higher incomes (pushing towards high income), while others were linked to lower incomes.\n",
      "\n",
      "**Similarities & Surprises:** Interestingly, both individuals are older men of White race and have a lot of the same “native-country” values as zero which is why they’re pulling in opposite directions. However, the model's reliance on \"native country\" is surprising – it suggests that the model might be picking up on correlations between origin and income that aren't necessarily based on individual skills or experience. It also highlights how seemingly small differences in features can drastically change a prediction. For example, Instance 1 had a significant capital gain while Instance 2 did not.\n",
      "\n",
      "**What does this tell us about the model?** This shows us that the model is sensitive to specific feature values and combinations. While it's trying to learn patterns, it's clearly picking up on correlations (like those related to \"native country\") that may be spurious or unfair. It also emphasizes the importance of capital gains as a predictor which makes sense - an increase in assets can lead to higher income. These errors highlight the need for careful evaluation and potential adjustments to the model to reduce bias and improve accuracy, especially when dealing with sensitive demographic information.\n",
      "\n",
      "\n",
      "\n",
      "**Important Note:** LIME explanations are just snapshots – they show *one* possible explanation for a specific prediction. The model's overall behavior is complex, and these explanations don’t capture everything.\n"
     ]
    }
   ],
   "source": [
    "# Compare two instances\n",
    "id1, id2 = mistake_indices[0], mistake_indices[1]\n",
    "print(f\"Comparing instances {id1} and {id2}...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison = compare_instances(id1, id2)\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26308e5f",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "### Summary of Task 6: Explainability & LLMs\n",
    "\n",
    "In this notebook, we built a **natural language interface** for explaining individual predictions made by our differentially private classifier. The key components:\n",
    "\n",
    "**Architecture Choices:**\n",
    "- **LIME** (Local Interpretable Model-agnostic Explanations) - Provides instance-specific feature importance that directly answers \"why this prediction\"\n",
    "- **Direct Context Injection** (not RAG) - Our explanation data is structured and small enough to inject directly into prompts\n",
    "- **LM Studio** with local LLM - Ensures data privacy by keeping everything local\n",
    "\n",
    "**Two-Tier Interface:**\n",
    "1. **Simple Function** (`explain_instance()`) - Quick, one-shot explanations for any instance\n",
    "2. **Chat Class** (`ExplainabilityChat`) - Interactive, conversational interface with memory\n",
    "\n",
    "**Key Insights from the Explanations:**\n",
    "- The private classifier relies heavily on **marital-status** and **relationship** features\n",
    "- Economic factors like **capital-gain** and **education** also play significant roles\n",
    "- Sensitive attributes (age, sex) have lower direct influence (by design, due to fairness constraints)\n",
    "\n",
    "**Limitations:**\n",
    "- LIME explanations are approximations of the model's true decision boundary\n",
    "- LLM responses depend on prompt quality and model capabilities\n",
    "- Local LLMs may have lower performance than cloud alternatives\n",
    "\n",
    "This approach successfully bridges the gap between technical ML explanations and human-understandable language, making the model's decisions accessible to non-technical stakeholders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
