{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28097133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from aif360.datasets import AdultDataset, BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix\n",
    " )\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e9c12",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# privileged and unprivileged groups\n",
    "privileged_groups = [{'sex': 1, 'age_binary': 1}] # old white males\n",
    "unprivileged_groups = [{'sex': 0, 'age_binary': 0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e08e51",
   "metadata": {},
   "source": [
    "### Custom preprocessing pipeline\n",
    "To align with the fairness experiments, we explicitly control how the Adult dataset encodes protected attributes. The block below binarizes age around the dataset median, maps race and sex to binary indicators, and removes the original age column so that downstream models only see the derived protected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom processing for the dataset\n",
    "def custom_preprocessing(df):\n",
    "    \"\"\"Binarize age, encode race/sex, and drop raw columns to expose protected attributes explicitly.\"\"\"\n",
    "    median_age = df['age'].median()\n",
    "    df['age_binary'] = (df['age'] > median_age).astype(float)\n",
    "    df.drop(columns=['age'], inplace=True)\n",
    "    df['race'] = (df['race'] == 'White').astype(float)\n",
    "    df['sex'] = (df['sex'] == 'Male').astype(float)\n",
    "    return df\n",
    "\n",
    "dataset = AdultDataset(custom_preprocessing=custom_preprocessing,\n",
    "                              protected_attribute_names=['age_binary', 'sex'],\n",
    "                              privileged_classes=[np.array([1.0]), np.array([1.0])] ) # old white males\n",
    "\n",
    "# Get the dataset and split into train and test\n",
    "np.random.seed(1)\n",
    "dataset_orig_train, dataset_orig_vt = dataset.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e938c5fe",
   "metadata": {},
   "source": [
    "#### Clean up training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6153e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_train = RW.fit_transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea094a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The 50 first instance weights originally:')\n",
    "print(dataset.instance_weights[:50])\n",
    "\n",
    "print('The 50 first instance weights after reweighing:')\n",
    "dataset_transf_train.instance_weights[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55c03e",
   "metadata": {},
   "source": [
    "## Train classifier on original/weighted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract features and labels ---\n",
    "def extract_xy(dataset):\n",
    "    \"\"\"Return numpy arrays of features and flattened labels for AIF360 datasets.\"\"\"\n",
    "    return dataset.features, dataset.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = extract_xy(dataset_orig_train)\n",
    "X_valid, y_valid = extract_xy(dataset_orig_valid)\n",
    "X_test,  y_test  = extract_xy(dataset_orig_test)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_transf, y_train_transf = extract_xy(dataset_transf_train)\n",
    "w_train_transf = dataset_transf_train.instance_weights\n",
    "X_train_transf_scaled = scaler.fit_transform(X_train_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d568251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression on the original split\n",
    "lr_classifier_origin = LogisticRegression(max_iter=1000)\n",
    "lr_classifier_origin.fit(X_train_scaled, y_train)\n",
    "y_test_orig_pred = lr_classifier_origin.predict(X_test_scaled)\n",
    "\n",
    "# Train the same model on reweighed data using instance weights\n",
    "lr_classifier_transf = LogisticRegression(max_iter=1000)\n",
    "lr_classifier_transf.fit(X_train_transf_scaled, y_train_transf,\n",
    "                         sample_weight=w_train_transf)\n",
    "y_test_transf_pred = lr_classifier_transf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337df30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_fairness_metrics(metric):\n",
    "    \"\"\"Collect commonly used fairness metrics from an AIF360 ClassificationMetric object.\"\"\"\n",
    "    return {\n",
    "        \"Statistical Parity Difference\": metric.statistical_parity_difference(),\n",
    "        \"Disparate Impact\": metric.disparate_impact(),\n",
    "        \"Average Odds Difference\": metric.average_odds_difference(),\n",
    "        \"Equal Opportunity Difference\": metric.equal_opportunity_difference(),\n",
    "        \"Balanced Accuracy (TPR/TNR avg)\": 0.5 * (metric.true_positive_rate() + metric.true_negative_rate())\n",
    "    }\n",
    "\n",
    "def plot_model_performance(model_name, y_true, y_pred):\n",
    "    \"\"\"Visualize scalar performance metrics and confusion matrix for a classifier.\"\"\"\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Metric\": list(metrics.keys()),\n",
    "        \"Value\": list(metrics.values())\n",
    "    })\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sns.barplot(data=metrics_df, x=\"Metric\", y=\"Value\", hue=\"Metric\", dodge=False, palette=\"viridis\", ax=axes[0])\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    axes[0].set_title(f\"{model_name} Metrics\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    legend = axes[0].get_legend()\n",
    "    if legend is not None:\n",
    "        legend.remove()\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[1])\n",
    "    axes[1].set_title(f\"{model_name} Confusion Matrix\")\n",
    "    axes[1].set_xlabel(\"Predicted\")\n",
    "    axes[1].set_ylabel(\"Actual\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return metrics\n",
    "\n",
    "def plot_fairness_comparison(metrics_a, metrics_b, labels=(\"No Reweighing\", \"Reweighing\")):\n",
    "    \"\"\"Plot side-by-side fairness metrics for two models to compare mitigation impact.\"\"\"\n",
    "    fairness_df = pd.DataFrame({\n",
    "        \"Metric\": list(metrics_a.keys()) + list(metrics_b.keys()),\n",
    "        \"Value\": list(metrics_a.values()) + list(metrics_b.values()),\n",
    "        \"Model\": [labels[0]] * len(metrics_a) + [labels[1]] * len(metrics_b)\n",
    "    })\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    sns.barplot(data=fairness_df, x=\"Metric\", y=\"Value\", hue=\"Model\", ax=ax)\n",
    "    ax.set_title(\"Fairness Metric Comparison\")\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "print(\"MODEL EVALUATION DASHBOARD\")\n",
    "\n",
    "# Visual diagnostics for the original and reweighed models\n",
    "metrics_orig = plot_model_performance(\"No Reweighing\", y_test, y_test_orig_pred)\n",
    "metrics_transf = plot_model_performance(\"Reweighing\", y_test, y_test_transf_pred)\n",
    "\n",
    "# Fairness metrics for both models\n",
    "dataset_orig_test_pred = dataset_orig_test.copy()\n",
    "dataset_orig_test_pred.labels = y_test_orig_pred\n",
    "metric_orig_test = ClassificationMetric(dataset_orig_test, dataset_orig_test_pred,\n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "fairness_metrics_orig = summarize_fairness_metrics(metric_orig_test)\n",
    "\n",
    "dataset_transf_test_pred = dataset_orig_test.copy()\n",
    "dataset_transf_test_pred.labels = y_test_transf_pred\n",
    "metric_transf_test = ClassificationMetric(dataset_orig_test, dataset_transf_test_pred,\n",
    "                                          unprivileged_groups=unprivileged_groups,\n",
    "                                          privileged_groups=privileged_groups)\n",
    "fairness_metrics_transf = summarize_fairness_metrics(metric_transf_test)\n",
    "\n",
    "# Compare fairness metrics side-by-side with a bar plot and styled table\n",
    "plot_fairness_comparison(fairness_metrics_orig, fairness_metrics_transf)\n",
    "fairness_table = pd.DataFrame({\n",
    "    \"Metric\": list(fairness_metrics_orig.keys()),\n",
    "    \"No Reweighing\": list(fairness_metrics_orig.values()),\n",
    "    \"Reweighing\": list(fairness_metrics_transf.values())\n",
    "})\n",
    "display(fairness_table.style.format({\"No Reweighing\": \"{:.4f}\", \"Reweighing\": \"{:.4f}\"}).set_caption(\"Fairness metrics summary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cbafc2",
   "metadata": {},
   "source": [
    "### Why statistical parity difference is not exactly zero\n",
    "Reweighing rebalances the training distribution but does not hard-constrain the downstream classifier. Logistic regression is still optimized for accuracy on the reweighted data, so slight disparities can reappear once the model is evaluated on unseen validation/test splits with their original distributions. Small residual SPD values therefore signal that the mitigation reduced—yet did not entirely eliminate—the gap. Further mitigation (e.g., stronger fairness regularizers or post-processing) would be required to drive SPD closer to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"COMPARISON\")\n",
    "print(f\"Original Model Accuracy:    {accuracy_score(y_test, y_test_orig_pred):.4f}\")\n",
    "print(f\"Transformed Model Accuracy: {accuracy_score(y_test, y_test_transf_pred):.4f}\")\n",
    "print(f\"Accuracy Difference:        {accuracy_score(y_test, y_test_transf_pred) - accuracy_score(y_test, y_test_orig_pred):.4f}\")\n",
    "print(f\"Original Model SPD:         {metric_orig_test.statistical_parity_difference():.4f}\")\n",
    "print(f\"Transformed Model SPD:      {metric_transf_test.statistical_parity_difference():.4f}\")\n",
    "print(f\"SPD Improvement:            {abs(metric_transf_test.statistical_parity_difference()) - abs(metric_orig_test.statistical_parity_difference()):.4f}\")\n",
    "print(\"Note: Statistical Parity Difference closer to 0 indicates better fairness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c4337",
   "metadata": {},
   "source": [
    "### Fairness requirements checklist\n",
    "- **Protected attributes**: Age (binarized) and Sex are explicitly encoded and tracked through AIF360 datasets, satisfying the requirement to focus on these groups.\n",
    "- **Classifier + fairness metric**: A baseline logistic regression model is trained and evaluated with statistical parity difference, disparate impact, average odds difference, and equal opportunity difference.\n",
    "- **Mitigation technique**: Reweighing is applied to the training data, producing a fairer model whose metrics are directly compared to the baseline.\n",
    "- **Reporting**: Visual dashboards plus the comparison table document the before/after fairness metrics, showing measurable improvement even if SPD is not exactly zero.\n",
    "\n",
    "✅ *Conclusion:* the fairness analysis portion of the project statement (pre-privacy) is complete. Next steps will involve repeating the same metric/mitigation workflow on the privacy-preserving dataset once it is available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
